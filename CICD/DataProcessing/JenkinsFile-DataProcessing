pipeline {
    agent any  // Jenkins 파이프라인이 실행될 에이전트를 지정
    triggers {
        GenericTrigger(
            genericVariables: [
                [key: 'USER_NAME', value: '$.pull_request.user.login', expressionType: 'JSONPath'],
                [key: 'IF_MERGED', value: '$.pull_request.merged', expressionType: 'JSONPath'],
                [key: 'BASE_BRANCH', value: '$.pull_request.base.ref', expressionType: 'JSONPath'],
                [key: 'LABEL', value: '$.pull_request.labels[*].name', expressionType: 'JSONPath']
            ],
            causeString: 'Triggered by GitHub Pull Request by ${USER_NAME}',
            token: 'nowdoboss-data-processing',
            printContributedVariables: false,
            printPostContent: false,
            regexpFilterText: '$IF_MERGED $BASE_BRANCH $LABEL',
            regexpFilterExpression: '(?=.*true)(?=.*develop)(?=.*Data-Processing)'
        )
    }

    stages {
        stage('Setup') {
            steps {
                script {
                    currentBuild.description = "Merge requested by: ${env.USER_NAME}"
                }
            }
        }

        stage('Transfer, Deploy, and Build Hadoop and Spark') {
            steps {
                script {
                    sshPublisher(
                        publishers: [
                            sshPublisherDesc(
                                configName: 'Sub Server SSH', // Sub Server 설정 이름
                                transfers: [
                                    sshTransfer(
                                        sourceFiles: 'CICD/DataProcessing/**/*', // Sub Server로 전송할 파일
                                        excludes: '', // 제외 파일 없음 (해당 코드 추가함으로써 환경변수 -> .env 파일도 같이 보내짐)
                                        remoteDirectory: 'develop/infra/jenkins', // 작업 디렉터리
                                        execCommand: '''
                                            cd develop/infra/jenkins/CICD/DataProcessing

                                            echo "하둡 + 스파크 (masater1) 컨테이너 구성 실행 상태 확인 중..."
                                            isHadoopRunning_master1=$(docker ps --filter name=master1 --filter status=running --format '{{.Names}}')
                                            echo "마스터 노드 실행 상태: ${isHadoopRunning_master1}"

                                            echo "하둡 + 스파크 (worker1) 컨테이너 구성 실행 상태 확인 중..."
                                            isHadoopRunning_worker1=$(docker ps --filter name=worker1 --filter status=running --format '{{.Names}}')
                                            echo "워커 노드-1 실행 상태: ${isHadoopRunning_worker1}"

                                            echo "하둡 + 스파크 (worker2) 컨테이너 구성 실행 상태 확인 중..."
                                            isHadoopRunning_worker2=$(docker ps --filter name=worker2 --filter status=running --format '{{.Names}}')
                                            echo "워커 노드-2 실행 상태: ${isHadoopRunning_worker2}"

                                            echo "하둡 + 스파크 (worker3) 컨테이너 구성 실행 상태 확인 중..."
                                            isHadoopRunning_worker3=$(docker ps --filter name=worker3 --filter status=running --format '{{.Names}}')
                                            echo "워커 노드-3 실행 상태: ${isHadoopRunning_worker3}"

                                            if [ -z "$isHadoopRunning_master1" ] || [ -z "$isHadoopRunning_worker1" ] || [ -z "$isHadoopRunning_worker2" ] || [ -z "$isHadoopRunning_worker3" ]; then
                                                echo "하둡 + 스파크 클러스터 빌드중..."
                                                docker-compose -f docker-compose-hadoop-spark.yml up --build -d
                                            else
                                                echo "하둡 스파크 클러스터가 이미 실행중입니다!"
                                            fi
                                        '''
                                    )
                                ],
                                verbose: true // 상세 로그 활성화
                            )
                        ]
                    )
                }
            }
        }
    }
}
