services:
  master1:
    build:
      context: .
      dockerfile: hd-spark-base.Dockerfile
    container_name: master1
    hostname: master1
    ports:
      - '${HADOOP_NAME_NODE_WEB_UI_PORT}:${HADOOP_NAME_NODE_WEB_UI_PORT}'
      - '${HADOOP_RESOURCE_MANAGER_WEB_UI_PORT}:${HADOOP_RESOURCE_MANAGER_WEB_UI_PORT}'
      - '${HADOOP_MAP_REDUCE_JOB_HISTORY_SERVER_WEB_UI_PORT}:${HADOOP_MAP_REDUCE_JOB_HISTORY_SERVER_WEB_UI_PORT}'
      - '${SPARK_MASTER_PORT}:${SPARK_MASTER_PORT}'
      - '${SPARK_MASTER_WEB_UI_PORT}:${SPARK_MASTER_WEB_UI_PORT}'
      - '${SPARK_HISTORY_SERVER_PORT}:${SPARK_HISTORY_SERVER_PORT}'
    volumes:
      - shared_keys:/shared_keys
    networks:
      nowdoboss-net:
    command: >
      /bin/bash -c "
      if [ ! -f /setup_completed ]; then
          echo 'Performing initial setup...';
          /usr/local/bin/setup-hadoop.sh &&
          /usr/local/bin/update-hosts.sh &&
          /usr/local/bin/init-ssh-keys.sh &&
          /usr/local/bin/collect-ssh-keys.sh 3 &&
          /usr/local/bin/master/setup-master-hadoop-env.sh &&
          /usr/local/bin/create-hdfs-log-dir.sh &&
          touch /setup_completed;
      else
          echo 'Skipping initial setup, already completed.';
      fi;
      /usr/local/bin/start-master.sh &&
      /usr/local/bin/start-history-server.sh
      "

  worker1:
    build:
      context: .
      dockerfile: hd-spark-base.Dockerfile
    container_name: worker1
    hostname: worker1
    volumes:
      - shared_keys:/shared_keys
    networks:
      nowdoboss-net:
    command: >
      /bin/bash -c "
      if [ ! -f /setup_completed ]; then
          echo 'Performing initial setup...';
          /usr/local/bin/setup-hadoop.sh &&
          /usr/local/bin/update-hosts.sh &&
          /usr/local/bin/init-ssh-keys.sh &&
          /usr/local/bin/collect-ssh-keys.sh 5 &&
          /usr/local/bin/worker/setup-worker-hadoop-env.sh &&
          touch /setup_completed;
      else
          echo 'Skipping initial setup, already completed.';
      fi;
      /usr/local/bin/start-slave.sh
      "

  worker2:
    build:
      context: .
      dockerfile: hd-spark-base.Dockerfile
    container_name: worker2
    hostname: worker2
    volumes:
      - shared_keys:/shared_keys
    networks:
      nowdoboss-net:
    command: >
      /bin/bash -c "
      if [ ! -f /setup_completed ]; then
          echo 'Performing initial setup...';
          /usr/local/bin/setup-hadoop.sh &&
          /usr/local/bin/update-hosts.sh &&
          /usr/local/bin/init-ssh-keys.sh &&
          /usr/local/bin/collect-ssh-keys.sh 7 &&
          /usr/local/bin/worker/setup-worker-hadoop-env.sh &&
          touch /setup_completed;
      else
          echo 'Skipping initial setup, already completed.';
      fi;
      /usr/local/bin/start-slave.sh
      "

  worker3:
    build:
      context: .
      dockerfile: hd-spark-base.Dockerfile
    container_name: worker3
    hostname: worker3
    volumes:
      - shared_keys:/shared_keys
    networks:
      nowdoboss-net:
    command: >
      /bin/bash -c "
      if [ ! -f /setup_completed ]; then
          echo 'Performing initial setup...';
          /usr/local/bin/setup-hadoop.sh &&
          /usr/local/bin/update-hosts.sh &&
          /usr/local/bin/init-ssh-keys.sh &&
          /usr/local/bin/collect-ssh-keys.sh 7 &&
          /usr/local/bin/worker/setup-worker-hadoop-env.sh &&
          touch /setup_completed;
      else
          echo 'Skipping initial setup, already completed.';
      fi;
      /usr/local/bin/start-slave.sh
      "

networks:
  nowdoboss-net:
    name: nowdoboss-net
    driver: bridge

volumes:
  shared_keys:
