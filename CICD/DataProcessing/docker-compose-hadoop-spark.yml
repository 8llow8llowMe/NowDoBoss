# 공통 명령어 정의
x-commands:
  master_command: &master_command >
    /bin/bash -c "
    if [ ! -f /setup_completed ]; then
        echo 'Performing initial setup...';
        /usr/local/bin/setup-hadoop.sh &&
        /usr/local/bin/update-hosts.sh &&
        /usr/local/bin/init-ssh-keys.sh &&
        /usr/local/bin/collect-ssh-keys.sh 3 &&
        /usr/local/bin/master/setup-master-hadoop-env.sh &&
        /usr/local/bin/create-hdfs-log-dir.sh &&
        touch /setup_completed;
    else
        echo 'Skipping initial setup, already completed.';
    fi;
    /usr/local/bin/start-master.sh &&
    /usr/local/bin/start-history-server.sh"

  worker_command: &worker_command >
    /bin/bash -c "
    if [ ! -f /setup_completed ]; then
        echo 'Performing initial setup...';
        /usr/local/bin/setup-hadoop.sh &&
        /usr/local/bin/update-hosts.sh &&
        /usr/local/bin/init-ssh-keys.sh &&
        /usr/local/bin/collect-ssh-keys.sh 7 &&
        /usr/local/bin/worker/setup-worker-hadoop-env.sh &&
        touch /setup_completed;
    else
        echo 'Skipping initial setup, already completed.';
    fi;
    /usr/local/bin/start-slave.sh"

# 서비스 정의
services:
  master1:
    build:
      context: . # Dockerfile 경로
      dockerfile: hd-spark-base.Dockerfile
    container_name: master1
    hostname: master1
    ports:
      - '${HADOOP_NAME_NODE_WEB_UI_PORT}:${HADOOP_NAME_NODE_WEB_UI_PORT}' # Hadoop NameNode Web UI
      - '${HADOOP_RESOURCE_MANAGER_WEB_UI_PORT}:${HADOOP_RESOURCE_MANAGER_WEB_UI_PORT}' # ResourceManager Web UI
      - '${HADOOP_MAP_REDUCE_JOB_HISTORY_SERVER_WEB_UI_PORT}:${HADOOP_MAP_REDUCE_JOB_HISTORY_SERVER_WEB_UI_PORT}' # MapReduce History Server
      - '${SPARK_MASTER_PORT}:${SPARK_MASTER_PORT}' # Spark Master Port
      - '${SPARK_MASTER_WEB_UI_PORT}:8080' # Spark Master Web UI
      - '${SPARK_HISTORY_SERVER_PORT}:${SPARK_HISTORY_SERVER_PORT}' # Spark History Server
    volumes:
      - shared_keys:/shared_keys # SSH 키 공유 볼륨
    networks:
      - nowdoboss-net # 공통 네트워크
    command: *master_command # 공통 master 명령어 사용

  worker1:
    build:
      context: .
      dockerfile: hd-spark-base.Dockerfile
    container_name: worker1
    hostname: worker1
    volumes:
      - shared_keys:/shared_keys # SSH 키 공유 볼륨
    networks:
      - nowdoboss-net # 공통 네트워크
    command: *worker_command # 공통 worker 명령어 사용

  worker2:
    build:
      context: .
      dockerfile: hd-spark-base.Dockerfile
    container_name: worker2
    hostname: worker2
    volumes:
      - shared_keys:/shared_keys # SSH 키 공유 볼륨
    networks:
      - nowdoboss-net # 공통 네트워크
    command: *worker_command # 공통 worker 명령어 사용

  worker3:
    build:
      context: .
      dockerfile: hd-spark-base.Dockerfile
    container_name: worker3
    hostname: worker3
    volumes:
      - shared_keys:/shared_keys # SSH 키 공유 볼륨
    networks:
      - nowdoboss-net # 공통 네트워크
    command: *worker_command # 공통 worker 명령어 사용

# 볼륨 정의
volumes:
  shared_keys: # SSH 키 공유를 위한 볼륨

# 네트워크 정의
networks:
  nowdoboss-net:
    name: nowdoboss-net
    driver: bridge
